{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras\n",
      "  Downloading https://files.pythonhosted.org/packages/ad/fd/6bfe87920d7f4fd475acd28500a42482b6b84479832bdc0fe9e589a60ceb/Keras-2.3.1-py2.py3-none-any.whl (377kB)\n",
      "Requirement already satisfied: h5py in c:\\users\\acer1\\anaconda3\\lib\\site-packages (from keras) (2.9.0)\n",
      "Requirement already satisfied: scipy>=0.14 in c:\\users\\acer1\\anaconda3\\lib\\site-packages (from keras) (1.2.1)\n",
      "Requirement already satisfied: numpy>=1.9.1 in c:\\users\\acer1\\anaconda3\\lib\\site-packages (from keras) (1.16.4)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in c:\\users\\acer1\\anaconda3\\lib\\site-packages (from keras) (1.1.0)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\users\\acer1\\anaconda3\\lib\\site-packages (from keras) (1.12.0)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in c:\\users\\acer1\\anaconda3\\lib\\site-packages (from keras) (1.0.8)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\acer1\\anaconda3\\lib\\site-packages (from keras) (5.1.1)\n",
      "Installing collected packages: keras\n",
      "Successfully installed keras-2.3.1\n"
     ]
    }
   ],
   "source": [
    "! pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pytorch_transformers import BertTokenizer, BertConfig\n",
    "from pytorch_transformers import AdamW, BertForSequenceClassification\n",
    "from tqdm import tqdm, trange\n",
    "import pandas as pd\n",
    "import io\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GeForce 940M GPUs\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "if device == torch.device('cpu'):\n",
    "    print('Using cpu')\n",
    "else:\n",
    "    n_gpu = torch.cuda.device_count()\n",
    "    print('Using {} GPUs'.format(torch.cuda.get_device_name(0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "classes = []\n",
    "n = 420 #количество классов\n",
    "\n",
    "for i in range(n):\n",
    "    classes.append(pd.read_csv(str(i)+'.csv', encoding='utf8', sep=';', header=None)) #создаем таблицы с данными"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = np.concatenate([i[1] for i in classes]) #все предложения\n",
    "\n",
    "sentences = [\"[CLS] \" + sentence + \" [SEP]\" for sentence in sentences]\n",
    "\n",
    "labels = []\n",
    "for i in range(n):\n",
    "    labels+=[[i] for _ in range(classes[i].shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(sentences) == len(labels) == pos_texts.shape[0] + neg_texts.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_sentences, test_sentences, train_gt, test_gt = train_test_split(sentences, labels, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    создание токенов\n",
    "'''\n",
    "from pytorch_transformers import BertTokenizer, BertConfig\n",
    "\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
    "\n",
    "tokenized_texts = [tokenizer.tokenize(sent) for sent in train_sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n",
    "input_ids = pad_sequences(\n",
    "    input_ids,\n",
    "    maxlen=100,\n",
    "    dtype=\"long\",\n",
    "    truncating=\"post\",\n",
    "    padding=\"post\"\n",
    ")\n",
    "attention_masks = [[float(i>0) for i in seq] for seq in input_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(\n",
    "    input_ids, train_gt, \n",
    "    random_state=42,\n",
    "    test_size=0.1\n",
    ")\n",
    "\n",
    "train_masks, validation_masks, _, _ = train_test_split(\n",
    "    attention_masks,\n",
    "    input_ids,\n",
    "    random_state=42,\n",
    "    test_size=0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inputs = torch.tensor(train_inputs)\n",
    "train_labels = torch.tensor(train_labels)\n",
    "train_masks = torch.tensor(train_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_inputs = torch.tensor(validation_inputs)\n",
    "validation_labels = torch.tensor(validation_labels)\n",
    "validation_masks = torch.tensor(validation_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
    "train_dataloader = DataLoader(\n",
    "    train_data,\n",
    "    sampler=RandomSampler(train_data),\n",
    "    batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
    "validation_dataloader = DataLoader(\n",
    "    validation_data,\n",
    "    sampler=SequentialSampler(validation_data),\n",
    "    batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Обучение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'n' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-51d3a41688d2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpytorch_transformers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mBertForQuestionAnswering\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBertForTokenClassification\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBertForSequenceClassification\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"bert-base-uncased\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_labels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'n' is not defined"
     ]
    }
   ],
   "source": [
    "from pytorch_transformers import AdamW, BertForSequenceClassification\n",
    "from pytorch_transformers import BertForQuestionAnswering, BertForTokenClassification\n",
    "\n",
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=n)\n",
    "model.to(device)\n",
    "\n",
    "param_optimizer = list(model.named_parameters())\n",
    "no_decay = ['bias', 'gamma', 'beta']\n",
    "optimizer_grouped_parameters = [\n",
    "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
    "     'weight_decay_rate': 0.01},\n",
    "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
    "     'weight_decay_rate': 0.0}\n",
    "]\n",
    "\n",
    "optimizer = AdamW(optimizer_grouped_parameters, lr=2e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "# Будем сохранять loss во время обучения\n",
    "# и рисовать график в режиме реального времени\n",
    "train_loss_set = []\n",
    "train_loss = 0\n",
    "\n",
    "\n",
    "# Обучение\n",
    "# Переводим модель в training mode\n",
    "model.train()\n",
    "\n",
    "\n",
    "for step, batch in enumerate(train_dataloader):\n",
    "    # добавляем батч для вычисления на GPU\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "    # Распаковываем данные из dataloader\n",
    "    b_input_ids, b_input_mask, b_labels = batch\n",
    "    \n",
    "    # если не сделать .zero_grad(), градиенты будут накапливаться\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # Forward pass\n",
    "    loss = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n",
    "\n",
    "    train_loss_set.append(loss[0].item())  \n",
    "    \n",
    "    # Backward pass\n",
    "    loss[0].backward()\n",
    "    \n",
    "    # Обновляем параметры и делаем шаг используя посчитанные градиенты\n",
    "    optimizer.step()\n",
    "\n",
    "    # Обновляем loss\n",
    "    train_loss += loss[0].item()\n",
    "    \n",
    "    # Рисуем график\n",
    "    clear_output(True)\n",
    "    plt.plot(train_loss_set)\n",
    "    plt.title(\"Training loss\")\n",
    "    plt.xlabel(\"Batch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.show()\n",
    "    \n",
    "print(\"Loss на обучающей выборке: {0:.5f}\".format(train_loss / len(train_dataloader)))\n",
    "\n",
    "\n",
    "# Валидация\n",
    "# Переводим модель в evaluation mode\n",
    "model.eval()\n",
    "\n",
    "valid_preds, valid_labels = [], []\n",
    "\n",
    "for batch in validation_dataloader:   \n",
    "    # добавляем батч для вычисления на GPU\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "    \n",
    "    # Распаковываем данные из dataloader\n",
    "    b_input_ids, b_input_mask, b_labels = batch\n",
    "    \n",
    "    # При использовании .no_grad() модель не будет считать и хранить градиенты.\n",
    "    # Это ускорит процесс предсказания меток для валидационных данных.\n",
    "    with torch.no_grad():\n",
    "        logits = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
    "\n",
    "    # Перемещаем logits и метки классов на CPU для дальнейшей работы\n",
    "    logits = logits[0].detach().cpu().numpy()\n",
    "    label_ids = b_labels.to('cpu').numpy()\n",
    "    \n",
    "    batch_preds = np.argmax(logits, axis=1)\n",
    "    batch_labels = np.concatenate(label_ids)     \n",
    "    valid_preds.extend(batch_preds)\n",
    "    valid_labels.extend(batch_labels)\n",
    "\n",
    "print(\"Процент правильных предсказаний на валидационной выборке: {0:.2f}%\".format(\n",
    "    accuracy_score(valid_labels, valid_preds) * 100\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Процент правильных предсказаний на валидационной выборке: {0:.2f}%\".format(\n",
    "    accuracy_score(valid_labels, valid_preds) * 100\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_texts = [tokenizer.tokenize(sent) for sent in test_sentences]\n",
    "input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n",
    "\n",
    "input_ids = pad_sequences(\n",
    "    input_ids,\n",
    "    maxlen=100,\n",
    "    dtype=\"long\",\n",
    "    truncating=\"post\",\n",
    "    padding=\"post\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_masks = [[float(i>0) for i in seq] for seq in input_ids]\n",
    "\n",
    "prediction_inputs = torch.tensor(input_ids)\n",
    "prediction_masks = torch.tensor(attention_masks)\n",
    "prediction_labels = torch.tensor(test_gt)\n",
    "\n",
    "prediction_data = TensorDataset(\n",
    "    prediction_inputs,\n",
    "    prediction_masks,\n",
    "    prediction_labels\n",
    ")\n",
    "\n",
    "prediction_dataloader = DataLoader(\n",
    "    prediction_data, \n",
    "    sampler=SequentialSampler(prediction_data),\n",
    "    batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "test_preds, test_labels = [], []\n",
    "\n",
    "for batch in prediction_dataloader:\n",
    "    # добавляем батч для вычисления на GPU\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "    \n",
    "    # Распаковываем данные из dataloader\n",
    "    b_input_ids, b_input_mask, b_labels = batch\n",
    "    \n",
    "    # При использовании .no_grad() модель не будет считать и хранить градиенты.\n",
    "    # Это ускорит процесс предсказания меток для тестовых данных.\n",
    "    with torch.no_grad():\n",
    "        logits = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
    "\n",
    "    # Перемещаем logits и метки классов на CPU для дальнейшей работы\n",
    "    logits = logits[0].detach().cpu().numpy()\n",
    "    label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "    # Сохраняем предсказанные классы и ground truth\n",
    "    batch_preds = np.argmax(logits, axis=1)\n",
    "    batch_labels = np.concatenate(label_ids)  \n",
    "    test_preds.extend(batch_preds)\n",
    "    test_labels.extend(batch_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
